# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
from langchain.tools.retriever import create_retriever_tool  # T·∫°o c√¥ng c·ª• t√¨m ki·∫øm
from langchain_openai import ChatOpenAI  # Model ng√¥n ng·ªØ OpenAI
from langchain.agents import AgentExecutor, create_openai_functions_agent  # T·∫°o v√† th·ª±c thi agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # X·ª≠ l√Ω prompt
from seed_data import seed_milvus, connect_to_milvus  # K·∫øt n·ªëi v·ªõi Milvus
import streamlit as st  # Framework UI
from langchain.callbacks import StreamlitCallbackHandler  # X·ª≠ l√Ω callback cho Streamlit
from langchain.memory import StreamlitChatMessageHistory  # L∆∞u tr·ªØ l·ªãch s·ª≠ chat
from langchain.retrievers import EnsembleRetriever  # K·∫øt h·ª£p nhi·ªÅu retriever
from langchain_community.retrievers import BM25Retriever  # Retriever d·ª±a tr√™n BM25
from langchain_core.documents import Document  # L·ªõp Document

def get_retriever() -> EnsembleRetriever:
    """
    T·∫°o m·ªôt ensemble retriever k·∫øt h·ª£p vector search (Milvus) v√† BM25
    Returns:
        EnsembleRetriever: Retriever k·∫øt h·ª£p v·ªõi t·ª∑ tr·ªçng:
            - 70% Milvus vector search (k=4 k·∫øt qu·∫£)
            - 30% BM25 text search (k=4 k·∫øt qu·∫£)
    Ch√∫ √Ω:
        - Y√™u c·∫ßu Milvus server ƒëang ch·∫°y t·∫°i localhost:19530
        - Collection 'data_test_live_v2' ph·∫£i t·ªìn t·∫°i trong Milvus
        - BM25 ƒë∆∞·ª£c kh·ªüi t·∫°o t·ª´ 100 document ƒë·∫ßu ti√™n trong Milvus
    """
    # K·∫øt n·ªëi v·ªõi Milvus v√† t·∫°o vector retriever
    vectorstore = connect_to_milvus('http://localhost:19530', 'data_test_live_v2')
    milvus_retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 4})

    # T·∫°o BM25 retriever t·ª´ to√†n b·ªô documents
    documents = [Document(page_content=doc.page_content, metadata=doc.metadata)
                 for doc in vectorstore.similarity_search("", k=100)]
    bm25_retriever = BM25Retriever.from_documents(documents)
    bm25_retriever.k = 4

    # K·∫øt h·ª£p hai retriever v·ªõi t·ª∑ tr·ªçng
    ensemble_retriever = EnsembleRetriever(
        retrievers=[milvus_retriever, bm25_retriever],
        weights=[0.7, 0.3]
    )
    return ensemble_retriever

# T·∫°o c√¥ng c·ª• t√¨m ki·∫øm cho agent
tool = create_retriever_tool(
    get_retriever(),
    "find",
    "Search for information of Stack AI."
)

def get_llm_and_agent(_retriever) -> AgentExecutor:
    """
    Kh·ªüi t·∫°o Language Model v√† Agent v·ªõi c·∫•u h√¨nh c·ª• th·ªÉ
    Args:
        _retriever: Retriever ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin
    Returns:
        AgentExecutor: Agent ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh v·ªõi:
            - Model: GPT-4
            - Temperature: 0
            - Streaming: Enabled
            - Custom system prompt
    Ch√∫ √Ω:
        - Y√™u c·∫ßu OPENAI_API_KEY ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh
        - Agent ƒë∆∞·ª£c thi·∫øt l·∫≠p v·ªõi t√™n "ChatchatAI"
        - S·ª≠ d·ª•ng chat history ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh h·ªôi tho·∫°i
    """
    # Kh·ªüi t·∫°o ChatOpenAI v·ªõi ch·∫ø ƒë·ªô streaming
    llm = ChatOpenAI(temperature=0, streaming=True, model="gpt-4")
    tools = [tool]
    
    # Thi·∫øt l·∫≠p prompt template cho agent
    system = """You are an expert at AI. Your name is ChatchatAI."""
    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # T·∫°o v√† tr·∫£ v·ªÅ agent
    agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)
    return AgentExecutor(agent=agent, tools=tools, verbose=True)

# Kh·ªüi t·∫°o retriever v√† agent
retriever = get_retriever()
agent_executor = get_llm_and_agent(retriever)

# === PH·∫¶N STREAMLIT UI ===
"""
Ph·∫ßn UI s·ª≠ d·ª•ng Streamlit v·ªõi c√°c t√≠nh nƒÉng:
1. Hi·ªÉn th·ªã ti√™u ƒë·ªÅ v√† m√¥ t·∫£
2. L∆∞u tr·ªØ l·ªãch s·ª≠ chat trong session state
3. Hi·ªÉn th·ªã tin nh·∫Øn d·∫°ng chat UI
4. X·ª≠ l√Ω input ng∆∞·ªùi d√πng v·ªõi streaming output
5. T√≠ch h·ª£p v·ªõi LangChain callbacks

C√°c th√†nh ph·∫ßn ch√≠nh:
- StreamlitChatMessageHistory: L∆∞u tr·ªØ l·ªãch s·ª≠ chat
- StreamlitCallbackHandler: X·ª≠ l√Ω streaming output
- st.session_state: Qu·∫£n l√Ω tr·∫°ng th√°i phi√™n l√†m vi·ªác
- st.chat_message: Hi·ªÉn th·ªã giao di·ªán chat

Lu·ªìng x·ª≠ l√Ω:
1. Ng∆∞·ªùi d√πng nh·∫≠p c√¢u h·ªèi
2. Hi·ªÉn th·ªã c√¢u h·ªèi trong giao di·ªán chat
3. G·ªçi agent ƒë·ªÉ x·ª≠ l√Ω v·ªõi chat history
4. Stream k·∫øt qu·∫£ v·ªÅ giao di·ªán
5. L∆∞u response v√†o l·ªãch s·ª≠
"""

# Kh·ªüi t·∫°o l∆∞u tr·ªØ l·ªãch s·ª≠ chat
msgs = StreamlitChatMessageHistory(key="langchain_messages")

# Thi·∫øt l·∫≠p giao di·ªán
st.title("üí¨ AI Assistant")
st.caption("üöÄ A Streamlit chatbot powered by LangChain and OpenAI")

# Kh·ªüi t·∫°o session state cho tin nh·∫Øn n·∫øu ch∆∞a c√≥
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "How can I help you?"}]
    msgs.add_ai_message("How can I help you?")

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for msg in st.session_state.messages:
    role = "assistant" if msg["role"] == "assistant" else "human"
    st.chat_message(role).write(msg["content"])

# X·ª≠ l√Ω input t·ª´ ng∆∞·ªùi d√πng
if prompt := st.chat_input("Ask me anything about Stack AI and related topics!"):
    # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o giao di·ªán
    st.session_state.messages.append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)
    msgs.add_user_message(prompt)

    # Hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa assistant
    with st.chat_message("assistant"):
        # T·∫°o container ƒë·ªÉ hi·ªÉn th·ªã streaming output
        st_callback = StreamlitCallbackHandler(st.container())
        
        # L·∫•y l·ªãch s·ª≠ chat (tr·ª´ tin nh·∫Øn m·ªõi nh·∫•t)
        chat_history = [
            {"role": msg["role"], "content": msg["content"]}
            for msg in st.session_state.messages[:-1]
        ]

        # G·ªçi agent ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi
        response = agent_executor.invoke(
            {
                "input": prompt,
                "chat_history": chat_history
            },
            {"callbacks": [st_callback]}
        )

        # Hi·ªÉn th·ªã v√† l∆∞u ph·∫£n h·ªìi
        output = response["output"]
        st.session_state.messages.append({"role": "assistant", "content": output})
        msgs.add_ai_message(output)
        st.write(output)